version: '3.8'

services:
  comfy-watcher:
    image: jeffmittens/comfy-watcher:latest

    environment:
      # ComfyUI Configuration
      - COMFYUI_URL=${COMFYUI_URL:-http://comfyui:8188}
      # AWS Configuration
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-west-2}
      - AWS_ROLE_NAME=${AWS_ROLE_NAME:-DndRole}

      
      # Application Configuration
      - LOG_LEVEL=${LOG_LEVEL:-DEBUG}
      - FAST_QUEUE_POLL_INTERVAL=${FAST_QUEUE_POLL_INTERVAL:-5}
      - SLOW_QUEUE_POLL_INTERVAL=${SLOW_QUEUE_POLL_INTERVAL:-10}
      - OUTPUT_FOLDER=/app/output
    volumes:
      - /opt/comfyui/output:/app/output
    secrets:
      - aws_secret_access_key
      - aws_access_key_id
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    networks:
      - comfy-network

  comfyui:
    # Replace with your ComfyUI container image
    image: ghcr.io/lecode-official/comfyui-docker:latest
    ports:
      - "8188:8188"
    volumes:
      - /opt/comfyui/models:/opt/comfyui/models:rw
      - /opt/comfyui/custom_nodes:/opt/comfyui/custom_nodes:rw
      - /opt/comfyui/output:/opt/comfyui/output:rw
    environment:
      USER_ID: "1000"
      GROUP_ID: "1000"
      EXTRA_ARGS: "--listen 0.0.0.0 --disable-smart-memory"
    networks:
      - comfy-network
    deploy:
      # GPU support handled at Docker Swarm node level
      # Ensure nodes with GPUs are labeled appropriately
      placement:
        constraints:
          - node.labels.gpu == true
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

networks:
  comfy-network:
    external: true
    name: comfy-network

secrets:
  aws_access_key_id:
    external: true
  aws_secret_access_key:
    external: true
